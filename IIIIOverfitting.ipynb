{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b331b3c-425e-4f6a-bfa0-cf1260ceeb49",
   "metadata": {},
   "source": [
    "__Overfitting:__  \n",
    "is a common problem in machine learning and statistical modeling where a model learns the training data too well, including its noise and outliers, leading to poor generalization to new, unseen data.  In essence, an overfitted model performs well on the training data but fails to perform accurately on test or validation data.  \n",
    "\n",
    "__Overfittening__ means being too confident in predictions that worked in the training data.  \n",
    "We mentioned the distinction between training data and test data, where a linear model with five predictor variables (like cabin size, sauna, the distance to lake) adjusted to predict the prices in training data including three cabins will dutifully replicate the three prices exactely.   \n",
    "\n",
    "Still it is clear that the perfect 'predictions' in the training data aren't a guarantee of perfect predictions for any other data. This, is essence, is an extreme case of overfitting.  \n",
    "\n",
    "__Training Data__  \n",
    "â€¢ Purpose: Is used to train the machine learning model. It is the data the model learns from, allowing them to understand pattterns, relationships, and features in data.   \n",
    "â€¢ Usage: During training the model adjusts its parameters(like weights in nural networks) based on this data to minimize errors and improve accurecy.  \n",
    "â€¢ Size: Typically, the majority of the available data is used for training to ensure the model has enough information to learn effectively. â€¢ Example: In a supervised learning scenario, if you are training a model to recognize a handwritten digits, the training data will consist of images of handwritten digits along with their correct labels. \n",
    "\n",
    "\n",
    "__Testing Data__  \n",
    "â€¢ purpose: Is used to evaluate the performance of the trained model, It serves as a bench mark to assess how well the model generalizes to new, unseen data.  \n",
    "â€¢ Usage: After the model has been trained, it is tested on the testing data to measures its accurecy, precision, recall, or other relevant metrics. The model should not have seen this data during trining, ensuring an unbiased evaluation.  \n",
    "â€¢ Size: A small portion of the available data is typically set aside as testing data. This ensures the model's performance is evaluated on data it has not been exposed during the training.  \n",
    "\n",
    "#### Key Differences:\n",
    "* Purpose:\n",
    "  * Training data: used to teach the model.\n",
    "  * Testing data: used to evaluate the model's performance in predicting.\n",
    "* Exposure to the model:\n",
    "  * Training data: the model sees these data during training phase.\n",
    "  * Testing data : the model dose not see this data during training , it      is used only for evaluation.\n",
    "* Impact on model:\n",
    "  * Training data: Directly influences the model's learning process and       parameter adjustment.\n",
    "  * Testing data: Used to assess how well the model has learned and how       it performs in new unseen data.\n",
    " \n",
    "#### Importance of the Distenction:  \n",
    "The separation of training and testing data is crucial to avoid overfitting and to ensure that the model can generalize well to new data. If the same data is udsed for both training and testing, it would give an overly optimistic estimate of the model's performance, as the model would essentially be \"tested\" on data it has already seen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "097a2c45-6e74-4dc7-80d4-fcee14b8e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "085f2293-a3fc-4f9d-8b2e-3d83d9f3d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin1 = {\"Size\": [66],\n",
    "          'Sauna': [4],\n",
    "          'Lake Distance': [15],\n",
    "          'Bath Room': [2],\n",
    "          'Neighbor Distance': [500], \n",
    "          'Predicted Price': [258250]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45993a01-4188-4501-af53-e41f42120c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin1 = pd.DataFrame(cabin1, index = ['Cabin1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "067c4cb7-160e-40de-ae84-27c4339f4058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Sauna</th>\n",
       "      <th>Lake Distance</th>\n",
       "      <th>Bath Room</th>\n",
       "      <th>Neighbor Distance</th>\n",
       "      <th>Predicted Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin1</th>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>258250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Size  Sauna  Lake Distance  Bath Room  Neighbor Distance  \\\n",
       "Cabin1    66      4             15          2                500   \n",
       "\n",
       "        Predicted Price  \n",
       "Cabin1           258250  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea279cd-1ad5-4ec2-902e-4567e50a6f13",
   "metadata": {},
   "source": [
    "Back to the tourism cabins in Finland ....  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b41e5-499b-4f03-9a5c-2da1499e25d7",
   "metadata": {},
   "source": [
    "### Note\n",
    "That this cabin is our \"test data\" point it is also included in the training data...  \n",
    "\n",
    "If we feed the cabin details back into the nearest neighbor method, it will simply find the exact same cabin in the training data and determine that it is the nearest neighbor of the test data point.  \n",
    "Therefore, it will predict the price as Â¢ 258,250.  \n",
    "Since this was the price in the test data, we find that the price is predicted exactly. The same goes for any other cabin in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dae877-dfcc-4666-9b2b-76907e366355",
   "metadata": {},
   "source": [
    "As you noticed, when we added more cabins in the training data than there were predictors (in our case five), __the linear model could no longer fit the training data perfectly.__    \n",
    "In other words, we would say that the training error is not zero: this happens vertually always when the __number of predictor variables is less than the sample size of any linear model (unless the data happen to be very special)__    \n",
    "\n",
    "Non-linear models, which we'll study  in the next chapter, allow more flexability but we may still get a very small training error if the samle sizeis larger than the number of predictor variables.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "052f7440-d286-42dd-9297-d3449d4f89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'size':[25, 39, 13, 82, 130],\n",
    "               'sauna size' :[2, 3, 2, 5, 6],\n",
    "               'distance to water' :[50, 10, 13, 20, 10],\n",
    "               'idoor bathrooms' :[1, 1, 1, 2, 2],\n",
    "               'neighbor proximity' :[500, 1000, 1000, 120, 600],\n",
    "               'price in Â¢(output)' :[127900, 222100, 143750, 268000, 460700]}\n",
    "\n",
    "table = pd.DataFrame(data, index=pd.MultiIndex.from_product([['Training Data'], ['Cabin1', 'Cabin2', 'Cabin3', 'Cabin4', 'Cabin5']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65e25cf1-52c3-4ea8-ac6c-fa6842de273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sauna size</th>\n",
       "      <th>distance to water</th>\n",
       "      <th>idoor bathrooms</th>\n",
       "      <th>neighbor proximity</th>\n",
       "      <th>price in Â¢(output)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Training Data</th>\n",
       "      <th>Cabin1</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin2</th>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin4</th>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin5</th>\n",
       "      <td>130</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>460700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      size  sauna size  distance to water  idoor bathrooms  \\\n",
       "Training Data Cabin1    25           2                 50                1   \n",
       "              Cabin2    39           3                 10                1   \n",
       "              Cabin3    13           2                 13                1   \n",
       "              Cabin4    82           5                 20                2   \n",
       "              Cabin5   130           6                 10                2   \n",
       "\n",
       "                      neighbor proximity  price in Â¢(output)  \n",
       "Training Data Cabin1                 500              127900  \n",
       "              Cabin2                1000              222100  \n",
       "              Cabin3                1000              143750  \n",
       "              Cabin4                 120              268000  \n",
       "              Cabin5                 600              460700  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ff310-5b4f-4398-b335-79ddc94def5f",
   "metadata": {},
   "source": [
    "(Predictor Varibles) < than (Sample Size of Training data) ...  \n",
    "Then, the (training error) is not zero ...  \n",
    "OR  \n",
    "The linear model could no longer fit the training data perfectly.  \n",
    "\n",
    "Also, most important observation is that (a small training error)(does not guarantee that the model actally predicts new data well)  \n",
    "\n",
    "Espaecially, if it is obtained by fitting a complex, possibly non-linear model to a small training data set.  \n",
    "\n",
    "In fact, a zero training error may still followed by very poor prediction accuracy on test data that does not overlap with the training data.  \n",
    "\n",
    "### How do avoid Overfitting:\n",
    "1- The first line of defense is splitting your data into training and testing data.  \n",
    "When you tain the model with one part of your original data and test its performance with another, you will have at least of some idea of how well your model generalising when using unseen data.  \n",
    "\n",
    "2- Second line, if you have still doubts about if the data split in a good way, is to split the data into n different sets, and train the model n times - each time with a different combination of n-1 sets, with the remaining set being used as a test set.  \n",
    "This way you will get n estimates on how your selected model performs when using unseen data.  \n",
    "This is called (leave-one-out-cross-validation) and it is one of the simplest ways of doing cross validation.    \n",
    "\n",
    "Since overfitting is such a pain in the neck in the realm of machine learning, many people have spent time and energy to come up with ways to combat it.  \n",
    "Most of these will be out of this course scope, but you can read about methods like (regularisation and dropout) both of which are examples of widely understood and used methods in both linear and logistic regression and nural networks....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95308cd-e134-447b-9566-2d869f8a296e",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Let's for a moment imagine you have a data set on 1000 email messages labeled as either spam or not. Out of 1000 messages, 990 are legitimate emails, and 10 are spam.  \n",
    "Then ypu split your data into training and test data sets in such a way that both labels are present in both sets in equal ratios, and then train a classifier in a data.  \n",
    "What would you set as baseline accuracy that your model has to outperform in order to be considered worthwhile?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02c8f673-a8a5-44fd-b023-9c70098ee8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_set = 1000\n",
    "legitimate_mails = 990\n",
    "spam_mails = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a2c6a0e-bfb5-4b8c-be1f-52a633adf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_accuracy = (f'{legitimate_mails/spam_mails} %'  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cebf614b-f23f-43c9-a921-e8fb5c49ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.0 %'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6148a8-ba72-4a5d-8738-4f17862b56f1",
   "metadata": {},
   "source": [
    "$$Great   Good      Bye$$  \n",
    "$$ðŸ‘ŠðŸ»ðŸ‘ŠðŸ»ðŸ‘ŠðŸ»ðŸ‘ŠðŸ»$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c83e9-f2bc-4227-ab03-81c28a399897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
